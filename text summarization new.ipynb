{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab57e991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Learning vs. Neural Networks: What’s the Difference?”Natural language processing is the driving force behind machine intelligence in many modern real-world applications. For a deeper dive into the nuances between these technologies and their learning approaches, see “AI vs. Machine Learning vs. Potential data sources include clinical notes, discharge summaries, clinical trial protocols and literature data.Sign up for an IBMid and create your IBM Cloud account. Deep contextual insights and values for key clinical attributes develop more meaningful data. There’s a good chance you’ve interacted with NLP in the form of voice-operated GPS systems, digital assistants, speech-to-text dictation software, customer service chatbots, and other consumer conveniences.\n"
     ]
    }
   ],
   "source": [
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "scraped_data = urllib.request.urlopen('https://www.ibm.com/cloud/learn/natural-language-processing')\n",
    "article = scraped_data.read()\n",
    "\n",
    "parsed_article = bs.BeautifulSoup(article,'lxml')\n",
    "\n",
    "paragraphs = parsed_article.find_all('p')\n",
    "\n",
    "article_text = \"\"\n",
    "\n",
    "for p in paragraphs:\n",
    "    article_text += p.text\n",
    "    \n",
    "    article_text = re.sub(r'\\[[0-9]*\\]', ' ', article_text)\n",
    "article_text = re.sub(r'\\s+', ' ', article_text)\n",
    "\n",
    "formatted_article_text = re.sub('[^a-zA-Z]', ' ', article_text )\n",
    "formatted_article_text = re.sub(r'\\s+', ' ', formatted_article_text)\n",
    "sentence_list = nltk.sent_tokenize(article_text)\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "word_frequencies = {}\n",
    "for word in nltk.word_tokenize(formatted_article_text):\n",
    "    if word not in stopwords:\n",
    "        if word not in word_frequencies.keys():\n",
    "            word_frequencies[word] = 1\n",
    "        else:\n",
    "            word_frequencies[word] += 1\n",
    "            \n",
    "            maximum_frequncy = max(word_frequencies.values())\n",
    "\n",
    "for word in word_frequencies.keys():\n",
    "    word_frequencies[word] = (word_frequencies[word]/maximum_frequncy)\n",
    "    \n",
    "    sentence_scores = {}\n",
    "for sent in sentence_list:\n",
    "    for word in nltk.word_tokenize(sent.lower()):\n",
    "        if word in word_frequencies.keys():\n",
    "            if len(sent.split(' ')) < 30:\n",
    "                if sent not in sentence_scores.keys():\n",
    "                    sentence_scores[sent] = word_frequencies[word]\n",
    "                else:\n",
    "                    sentence_scores[sent] += word_frequencies[word]\n",
    "                    \n",
    "                    import heapq\n",
    "summary_sentences = heapq.nlargest(7, sentence_scores, key=sentence_scores.get)\n",
    "\n",
    "summary = ' '.join(summary_sentences)\n",
    "print(summary)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49298778",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
